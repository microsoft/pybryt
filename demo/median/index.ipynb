{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Runner\n",
    "\n",
    "This notebook demonstrates how to create a grading workflow using PyBryt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybryt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo has the following directory structure. This notebook, `index.ipynb`, runs PyBryt, `median.ipynb` is the assignment reference implementation, and `submissions` contains notebooks with student code in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "├── index.ipynb\n",
      "├── median-ref.pkl\n",
      "├── median.ipynb\n",
      "└── submissions\n",
      "    ├── subm01.ipynb\n",
      "    ├── subm02.ipynb\n",
      "    ├── subm03.ipynb\n",
      "    ├── subm04.ipynb\n",
      "    ├── subm05.ipynb\n",
      "    └── subm06.ipynb\n",
      "\n",
      "1 directory, 9 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Implementations\n",
    "\n",
    "If you have marked up a reference implementation, like the one in [`median.ipynb`](median.ipynb), you can load this reference using `pybryt.ReferenceImplementation.compile`. Because references are relatively static and can take some time to execute, you can pickle the reference implementations to a file with `pybryt.ReferenceImplementation.dump`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pybryt.ReferenceImplementation.compile(\"median.ipynb\")\n",
    "ref.dump(\"median-ref.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a pickled reference implementation, use `pybryt.ReferenceImplementation.load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pybryt.reference.ReferenceImplementation at 0x1062972e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = pybryt.ReferenceImplementation.load(\"median-ref.pkl\")\n",
    "ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Submissions\n",
    "\n",
    "To use PyBryt for grading multiple submissions, you can build a reproducible grading pipeline for an arbitrary number of submissions. To grab the submission notebook paths, the cell below uses `glob.glob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['submissions/subm01.ipynb',\n",
       " 'submissions/subm02.ipynb',\n",
       " 'submissions/subm03.ipynb',\n",
       " 'submissions/subm04.ipynb',\n",
       " 'submissions/subm05.ipynb',\n",
       " 'submissions/subm06.ipynb']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "subms = sorted(glob(\"submissions/*.ipynb\"))\n",
    "subms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use PyBryt to grade a student's submission, a `pybryt.StudentImplementation` must be created from that submission. The constructor takes the path to the notebook as its only positional argument. It is in this step that the student's code is executed, so this cell will need to be rerun whenever changes are made to the submission notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pybryt.student.StudentImplementation at 0x106338908>,\n",
       " <pybryt.student.StudentImplementation at 0x104ec50b8>,\n",
       " <pybryt.student.StudentImplementation at 0x1062d6ba8>,\n",
       " <pybryt.student.StudentImplementation at 0x1063326a0>,\n",
       " <pybryt.student.StudentImplementation at 0x106343eb8>,\n",
       " <pybryt.student.StudentImplementation at 0x106357198>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_impls = []\n",
    "for subm in subms:\n",
    "    student_impls.append(pybryt.StudentImplementation(subm))\n",
    "\n",
    "student_impls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created the `pybryt.StudentImplementation` objects, use the `pybryt.StudentImplementation.check` method to run the check of a submission against a reference implementation. This method returns a single `pybryt.ReferenceResult` or a list of them, depending on the argument passed to `check`. In the cell below, the results are collected into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ReferenceResult([\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value)\n",
       " ]),\n",
       " ReferenceResult([\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value)\n",
       " ]),\n",
       " ReferenceResult([\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value)\n",
       " ]),\n",
       " ReferenceResult([\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value)\n",
       " ]),\n",
       " ReferenceResult([\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=False, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value)\n",
       " ]),\n",
       " ReferenceResult([\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value),\n",
       "   AnnotationResult(satisfied=True, annotation=pybryt.Value)\n",
       " ])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for si in student_impls:\n",
    "    results.append(si.check(ref))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the results in a concise manner, the `pybryt.ReferenceResult` class has some helpful instance variables. You can also get information about the memory footprint, such as the number of steps, from the `pybryt.StudentImplementation` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBMISSION: submissions/subm01.ipynb\n",
      "  EXECUTION STEPS: 106842\n",
      "  SATISFIED: True\n",
      "  MESSAGES:\n",
      "    - SUCCESS: Sorted the sample correctly\n",
      "    - SUCCESS: Computed the size of the sample\n",
      "    - SUCCESS: Sorted the sample correctly\n",
      "    - SUCCESS: Computed the size of the sample\n",
      "    - computed the correct median\n",
      "\n",
      "\n",
      "SUBMISSION: submissions/subm02.ipynb\n",
      "  EXECUTION STEPS: 101316\n",
      "  SATISFIED: False\n",
      "  MESSAGES:\n",
      "    - ERROR: The sample was not sorted\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - ERROR: The sample was not sorted\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - computed the correct median\n",
      "\n",
      "\n",
      "SUBMISSION: submissions/subm03.ipynb\n",
      "  EXECUTION STEPS: 102576\n",
      "  SATISFIED: False\n",
      "  MESSAGES:\n",
      "    - SUCCESS: Sorted the sample correctly\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - SUCCESS: Sorted the sample correctly\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - computed the correct median\n",
      "\n",
      "\n",
      "SUBMISSION: submissions/subm04.ipynb\n",
      "  EXECUTION STEPS: 97194\n",
      "  SATISFIED: False\n",
      "  MESSAGES:\n",
      "    - ERROR: The sample was not sorted\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - ERROR: The sample was not sorted\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - computed the correct median\n",
      "\n",
      "\n",
      "SUBMISSION: submissions/subm05.ipynb\n",
      "  EXECUTION STEPS: 95908\n",
      "  SATISFIED: False\n",
      "  MESSAGES:\n",
      "    - ERROR: The sample was not sorted\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - ERROR: The sample was not sorted\n",
      "    - ERROR: Did not capture the size of the set to determine if it is odd or even\n",
      "    - computed the correct median\n",
      "\n",
      "\n",
      "SUBMISSION: submissions/subm06.ipynb\n",
      "  EXECUTION STEPS: 108676\n",
      "  SATISFIED: True\n",
      "  MESSAGES:\n",
      "    - SUCCESS: Sorted the sample correctly\n",
      "    - SUCCESS: Computed the size of the sample\n",
      "    - SUCCESS: Sorted the sample correctly\n",
      "    - SUCCESS: Computed the size of the sample\n",
      "    - computed the correct median\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textwrap import indent\n",
    "for sp, si, res in zip(subms, student_impls, results):\n",
    "    print(f\"SUBMISSION: {sp}\")\n",
    "    print(f\"  EXECUTION STEPS: {si.steps}\") # the number of steps in the execution\n",
    "\n",
    "    # res.messages is a list of messages returned by the reference during grading\n",
    "    messages = \"\\n\".join(res.messages) \n",
    "    \n",
    "    # res.correct is a boolean for whether the reference was satisfied\n",
    "    message = f\"SATISFIED: {res.correct}\\nMESSAGES:\\n{indent(messages, '  - ')}\"\n",
    "    \n",
    "    # some pretty-printing\n",
    "    print(indent(message, \"  \"))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also turn the reference result objects into a JSON-friendly dictionary format for further processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'group': None,\n",
       " 'results': [{'satisfied': True,\n",
       "   'satisfied_at': 48156,\n",
       "   'annotation': {'name': 'Annotation 1',\n",
       "    'group': None,\n",
       "    'limit': None,\n",
       "    'success_message': 'SUCCESS: Sorted the sample correctly',\n",
       "    'failure_message': 'ERROR: The sample was not sorted',\n",
       "    'children': [],\n",
       "    'type': 'value',\n",
       "    'invariants': [],\n",
       "    'tol': 0},\n",
       "   'children': []},\n",
       "  {'satisfied': True,\n",
       "   'satisfied_at': 48151,\n",
       "   'annotation': {'name': 'Annotation 2',\n",
       "    'group': None,\n",
       "    'limit': None,\n",
       "    'success_message': 'SUCCESS: Computed the size of the sample',\n",
       "    'failure_message': 'ERROR: Did not capture the size of the set to determine if it is odd or even',\n",
       "    'children': [],\n",
       "    'type': 'value',\n",
       "    'invariants': [],\n",
       "    'tol': 0},\n",
       "   'children': []},\n",
       "  {'satisfied': True,\n",
       "   'satisfied_at': 48156,\n",
       "   'annotation': {'name': 'Annotation 3',\n",
       "    'group': None,\n",
       "    'limit': None,\n",
       "    'success_message': 'SUCCESS: Sorted the sample correctly',\n",
       "    'failure_message': 'ERROR: The sample was not sorted',\n",
       "    'children': [],\n",
       "    'type': 'value',\n",
       "    'invariants': [],\n",
       "    'tol': 0},\n",
       "   'children': []},\n",
       "  {'satisfied': True,\n",
       "   'satisfied_at': 48151,\n",
       "   'annotation': {'name': 'Annotation 4',\n",
       "    'group': None,\n",
       "    'limit': None,\n",
       "    'success_message': 'SUCCESS: Computed the size of the sample',\n",
       "    'failure_message': 'ERROR: Did not capture the size of the set to determine if it is odd or even',\n",
       "    'children': [],\n",
       "    'type': 'value',\n",
       "    'invariants': [],\n",
       "    'tol': 0},\n",
       "   'children': []},\n",
       "  {'satisfied': True,\n",
       "   'satisfied_at': 48147,\n",
       "   'annotation': {'name': 'Annotation 5',\n",
       "    'group': None,\n",
       "    'limit': None,\n",
       "    'success_message': 'computed the correct median',\n",
       "    'failure_message': 'failed to compute the median',\n",
       "    'children': [],\n",
       "    'type': 'value',\n",
       "    'invariants': [],\n",
       "    'tol': 0},\n",
       "   'children': []}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = results[0]\n",
    "res.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
